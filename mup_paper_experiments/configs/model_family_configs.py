from dataclasses import dataclass

@dataclass
class ModelConfig:
    wandb_run_name: int
    n_embd: int
    n_layer: int
    n_head: int
    n_kv_head: int
    block_size: int = 8192
    prod_sbatch_nodes: int = 1
    prod_n_gpus: int = 1
    prod_gradient_accumulation_steps: int = 1
    prod_batch_size: int = 1
    prod_max_iters: int = 30
    prod_sbatch_mem: int = 256
    noprod_max_iters: int = 30
    enable_fsdp: str = 'false'
    decay_lr: str = 'true'
    decay_profile: str = 'cosine'
    dataset: str = 'openwebtext'

    def get_config(self, prod: bool):
        base_config = {
            'wandb_run_name': self.wandb_run_name,
            'n_embd': self.n_embd,
            'n_layer': self.n_layer,
            'n_head': self.n_head,
            'n_kv_head': self.n_kv_head,
            'block_size': self.block_size,
            'decay_lr': self.decay_lr,
            'decay_profile': self.decay_profile,
        }
        if prod:            
            prod_config = {
                'sbatch_nodes': self.prod_sbatch_nodes,
                'n_gpus': self.prod_n_gpus,
                'gradient_accumulation_steps': self.prod_gradient_accumulation_steps,
                'batch_size': self.prod_batch_size,
                'max_iters': self.prod_max_iters,
                'sbatch_mem': self.prod_sbatch_mem,
                'enable_fsdp': self.enable_fsdp,
            }
        else:
            prod_config = {
                'sbatch_nodes': self.prod_sbatch_nodes,
                'n_gpus': self.prod_n_gpus,
                'gradient_accumulation_steps': self.prod_gradient_accumulation_steps,
                'batch_size': self.prod_batch_size,
                'max_iters': self.noprod_max_iters,
                'sbatch_mem': self.prod_sbatch_mem,
                'enable_fsdp': self.enable_fsdp,
            }

        return {**base_config, **prod_config}

common_args = {
    'decay_lr': 'true',
    
}

# Width Only
width_only = [
    ModelConfig(
        wandb_run_name='wo_small',
        n_embd=512, 
        n_layer=3, 
        n_head=8, 
        n_kv_head=8,
        prod_sbatch_nodes=1, 
        prod_n_gpus=4, 
        prod_gradient_accumulation_steps=4, 
        prod_batch_size=6, 
        prod_max_iters=1252, 
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='wo_medium',
        n_embd=640,
        n_layer=3,
        n_head=10,
        n_kv_head=10,
        prod_sbatch_nodes=1,
        prod_n_gpus=4,
        prod_gradient_accumulation_steps=4,
        prod_batch_size=7,
        prod_max_iters=1485,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='wo_large',
        n_embd=768,
        n_layer=3,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=5,
        prod_gradient_accumulation_steps=5,
        prod_batch_size=6,
        prod_max_iters=1649,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='wo_xlarge',
        n_embd=1024,
        n_layer=3,
        n_head=16,
        n_kv_head=16,
        prod_sbatch_nodes=1,
        prod_n_gpus=6,
        prod_gradient_accumulation_steps=6,
        prod_batch_size=6,
        prod_max_iters=2060,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]

# Depth Only
depth_only = [
    ModelConfig(
        wandb_run_name='do_small',
        n_embd=768,
        n_layer=2,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=5,
        prod_gradient_accumulation_steps=5,
        prod_batch_size=3,
        prod_max_iters=1380,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='do_medium',
        n_embd=768,
        n_layer=4,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=6,
        prod_gradient_accumulation_steps=6,
        prod_batch_size=3,
        prod_max_iters=1532,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='do_large',
        n_embd=768,
        n_layer=8,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=6,
        prod_gradient_accumulation_steps=6,
        prod_batch_size=3,
        prod_max_iters=1835,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='do_xlarge',
        n_embd=768,
        n_layer=16,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2317,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]

# Joint Width and Depth
joint_width_depth = [
    ModelConfig(
        wandb_run_name='jwd_small',
        n_embd=384,
        n_layer=4,
        n_head=6,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=4,
        prod_gradient_accumulation_steps=4,
        prod_batch_size=3,
        prod_max_iters=966,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='jwd_medium',
        n_embd=768,
        n_layer=6,
        n_head=12,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=6,
        prod_gradient_accumulation_steps=6,
        prod_batch_size=3,
        prod_max_iters=1649,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='jwd_large',
        n_embd=1024,
        n_layer=10,
        n_head=16,
        n_kv_head=16,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2497,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
     ModelConfig(
        wandb_run_name='jwd_xlarge',
        n_embd=1280,
        n_layer=12,
        n_head=20,
        n_kv_head=20,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=4,
        prod_max_iters=3234,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]

# Head Size
head_size = [
    ModelConfig(
        wandb_run_name='hs_32',
        n_embd=192,
        n_layer=3,
        n_head=6,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=2,
        prod_gradient_accumulation_steps=2,
        prod_batch_size=4,
        prod_max_iters=574,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='hs_64',
        n_embd=384,
        n_layer=3,
        n_head=6,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=4,
        prod_gradient_accumulation_steps=4,
        prod_batch_size=3,
        prod_max_iters=901,
        prod_sbatch_mem=256,
    ),
    ModelConfig(
        wandb_run_name='hs_128',
        n_embd=768,
        n_layer=3,
        n_head=6,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=5,
        prod_gradient_accumulation_steps=5,
        prod_batch_size=3,
        prod_max_iters=1461,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='hs_256',
        n_embd=1536,
        n_layer=3,
        n_head=6,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2375,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]

# KV Reps
kv_reps = [
    ModelConfig(
        wandb_run_name='kvr_1',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=1,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2267,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_2',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=2,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2276,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_4',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=4,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2294,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_6',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=6,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2312,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_8',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=8,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2330,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_12',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=12,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2366,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='kvr_24',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=24,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2375,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]

# Joint GQA
joint_gqa = [
    ModelConfig(
        wandb_run_name='gqa_1',
        n_embd=1536,
        n_layer=3,
        n_head=48,
        n_kv_head=24,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2366,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='gqa_2',
        n_embd=1536,
        n_layer=3,
        n_head=24,
        n_kv_head=8,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2330,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='gqa_3',
        n_embd=1536,
        n_layer=3,
        n_head=12,
        n_kv_head=3,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2312,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
    ModelConfig(
        wandb_run_name='gqa_4',
        n_embd=1536,
        n_layer=3,
        n_head=6,
        n_kv_head=1,
        prod_sbatch_nodes=1,
        prod_n_gpus=8,
        prod_gradient_accumulation_steps=8,
        prod_batch_size=3,
        prod_max_iters=2294,
        prod_sbatch_mem=256,
        enable_fsdp='true',
    ),
]